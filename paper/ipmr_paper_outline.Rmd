---
title: "ipmr Paper"
author: "Sam Levin"
date: "7/9/2019"
output: html_document
---

Coauthors - SCL, RSG, TMK, AC, DZC

## Intro

1. Integral projection models (IPMs) have become one of the tools of choice for discrete time demographers studying structured populations. Since Easterling, Ellner & Dixon's (2000) seminal paper, there have been XXX publications using IPMs. Their main power lies in the fact that they allow for continuously distributed state variables to describe vital rates, as opposed to historically favored methods that relied on sometimes arbitrary delineation of classes.

IPMs are flexible models that rely on raw data to drive their functional form. Regression analysis has been a standard tool for ecologists for quite some time now, and the field is mature enough to accomodate almost any type of data (e.g. Wood 2011, Bates et al. 2015). Regression models are usually easier to estimate than matrix parameters when data sets are small, facilitating analysis of population dynamics for threatened or endangered species in a way that matrix models cannot (Ramula et al. 2009). This flexibility has lead to an exponential increase in their appearance in the literature (Figure 1), and there are few signs that the model will fall out of favor soon.


*Point about flexibility, lead to figure 1*

```{r figure 1, eval = FALSE}

# Figure 1 - N_publications ~ Year + (Year|model_type)

```


2. To date, there has been only one serious effort to implement an R package to assist with integral projection modeling: `IPMpack` (Metcalf et al. XXXX). `IPMpack` was a major leap forward in allowing users to go from raw data to a set of iteration kernels in a matter of a few lines of code. Indeed, a number of the authors of `ipmr` have used it to great effect on their own data, as well as in teaching how to fit IPMs to students and mentees. Unfortunately, `IPMpack` is not a fully generalized set of tools, and there are certain types of models that it struggles or outright fails to implement. Furthermore, as of March 2020, it is no longer available from CRAN, and thus requires some effort for users to install. For example:
    
    + The interface for general IPMs (sensu Ellner, Rees & Childs 2016) is quite clunky, and requires detailed knowledge of the internal class structure to implement, for example, an age x size IPM.
    
    + Continuously varying environments are quite tricky to model, if not impossible.
    
    + It includes only two methods for integration - cumulative density functions and the midpoint rule for PDFs. This is problematic when vital rate functions are largely deterministic and generate spiky kernels (e.g. growth in long-lived trees). 
    
    + The common thread here is that it is operating at too high of a level of abstraction.
    
        + S4  obfuscates much of what is going on, and makes defining highly customized models far more difficult.
        
        + Less flexible vital rate models without an exceptional understanding of S4 OOP.
            
            + Even with a detailed understanding, incorporating complex sets of covariates is difficult.
        
    + Cannot model multiple continuous state variables.

    + Above points can actually hinder learning the methods in the long run, as they don't require a user to understand the fundamentals of what is going on with an IPM.
    
All of the above points are basically just critiques of using OOP to try to tackle the IPM problem. For example, if one wanted to fit a GAM for survival with `IPMpack`, then one would be in trouble, as the standard `makeSurvObj` function allows for `glm`'s and a subset of functions from `nlme`.  A functional programming approach allows us to define a more general, domain-specific language that does not constrict what types of models are available. 

## What makes us different??

`ipmr` is a lower-level framework that uses mathematical and/or _R_ expressions, rather than model objects, to generate iteration kernels. Importantly, it does not try to abstract away the actual vital rate model fitting process - we feel that is a substantially different question (e.g. how to model vital rates is a statistical question, not a model implementation one) that is best left to the user. This also means that users are free to specify vital rate models of *any* functional form. 

`ipmr` is largely powered by `rlang` (Henry & Wickham 2019) and works by building up expressions that reference each other at higher and higher levels in the model hierarchy. `ipmr` is relatively dependency-free, requiring only `rlang`, `purrr`, and `magrittr` (in addition to a few of the packages included in the base R distribution e.g. `graphics`, `utils`). 

The package itself can handle any set of valid R code that is presented to it, so user-specified functions, in addition to ones available from other packages, can all be included in the expressions that the user passes to `ipmr` functions. Figure 2 shows a generic IPM workflow from collecting the raw data to biological inference, highlighting the stages at which `ipmr` is useful.


```{r figure 2, fig.cap = "Example workflow chart. Definitely need revision!", echo = FALSE}

library(DiagrammeR)

grViz("digraph flowchart {
      node[fontname = Helvetica, shape = rectangle]
      tab1[label = '@@1']
      tab2[label = '@@2']
      tab3[label = '@@3']
      tab4[label = '@@4']
      tab5[label = '@@5']
      tab6[label = '@@6']
      tab1[label = '@@7']
      
      tab1 -> tab2 -> tab3 -> tab4 -> tab5 -> tab6 -> tab7;
      }
      
      [1]: 'Collect data in the field'
      [2]: 'Fit vital rate models using other packages (e.g. lme4, nlme, mgcv, brms)'
      [3]: 'Move coefficients or model objects into a named list'
      [4]: 'Decide whether the model is stochastic or deterministic and init_ipm() using the appropriate class'
      [5]: 'Build expressions for the individual kernels (e.g. P = s_g_mult(s, g)). When models are implemented from hierarchical vital rate models, take advantage of built-in suffix recognition in ipmr!'
      [6]: 'Build expressions for the individual vital rates using mathematical syntax, R functions, or some combination thereof (e.g. s = inv_logit(s_int, s_slope, sv_1))' 
      [7]: 'Generate an implementation argument list, define domains, and make_ipm()'
      
      ")

```


```{r table 1, echo = FALSE}
library(tibble)
library(knitr)
library(kableExtra)

knitr::kable(
  tibble::tribble(
    ~Feature,                                                  ~ipmr,  ~IPMpack,
    "Implement simple kernels",                                  "X",       "X",
    "Implement discrete/continuous combinations",                "X",       "X",
    "Basic implementation diagnostics",                          "X",       "X",
    "Fully customizable vital rate functions",                   "X",       "No",
    "Age-specific demographic functions",                        "In prep", "X",
    "Plot, print methods",                                       "X",       "X",
    "Model discretely varying environemnts",                     "X",       "X",
    "Model continuously varying environments",                   "X",       "Sort of",
    "Multiple continuous state variables",                       "X",       "No",
    "Density dependent models",                                  "In prep", "No",
    "Common underlying data structure for all models",           "X",       "No",
    "Available on CRAN",                                         "X",       "No"
    
  ),
  format = 'html',
  escape = FALSE,
  caption = "Table 1: Comparison of ipmr and IPMpack features."
) %>%
  column_spec(1, border_left = TRUE) %>%
  column_spec(2, border_left =  TRUE, border_right = TRUE) %>%
  column_spec(3, border_right = TRUE) %>%
  kable_styling()

```

At the core of `ipmr` is the `proto_ipm` data structure. It is a data frame containing all the information necessary to implement each sub-kernel, as well as the information needed to the full model. It specifies model ID's, kernel IDs, 

Introduce the `proto_ipm` data structure - becomes a key point in the discussion and sets up the idea of the common link between user- and database-specified IPMs.

4. Highlight flexibility - Table 2 w/ classes, descriptions!!!!!!!.


```{r table 2 }


knitr::kable(
  tibble::tribble(
    ~Class,                                                          ~Completed, 
    "Simple, density independent, deterministic",                     'Yes',           
    "Simple, density independent, stochastic, kernel-resampled",      'Yes',
    "Simple, density independent, stochastic, parameter-resampled",   "Yes",
    
    "General, density independent, deterministic",                    "Yes",
    "General, density independent, stochastic, kernel-resampled",     "Yes",
    "General, density independent, stochastic, parameter-resampled",  "Yes",
    
    "Simple, density depdendent, deterministic",                      "No",
    "Simple, density depdendent, stochastic, kernel-resampled",       "No",
    "Simple, density depdendent, stochastic, parameter-resampled",    "No",
    
    "General, density depdendent, deterministic",                     "No",
    "General, density depdendent, stochastic, kernel-resampled",      "No",
    "General, density depdendent, stochastic, parameter-resampled",   "No"
    
  ),
  format = 'html',
  escape = FALSE,
  caption = "Table 2: Implemented methods for make_ipm()."
) %>%
  column_spec(1, border_left = TRUE) %>%
  column_spec(2, border_left =  TRUE, border_right = TRUE) %>%
  kable_styling()



```

## Examples 

5. Case study - implement a `simple_di_det` and `general_dd_stoch_kern` to illustrate the different ways that it can be used to implement IPMs.

    + Focus here on commonality of code structure - the general example *shouldn't* include much more than the simple one.
    
    + make sure to demonstrate all `define_*` functions and key differences between `define_kernel` and `define_k`, but do not introduce all of the helpers here - save those for a vignette or something.
    
    + emphasize completeness of documentation - every function has help pages, examples in a vignette, and almost all are unit tested (this should change to ALL EXPORTED FUNCTIONS before publication)
    
```{r Figure 3, eval = FALSE}

# Figure 3 - diagnostic plots and general output from plot.* methods in ipmr



```
    
    
```{r Case Studies, eval = FALSE}
library(ipmr)
library(rlang)
library(purrr)

# NOTE SCL 7/9/19 - Should create some function that takes a set of desired names,
# a set of random effect estimates, and a list of fixed effect parameter estimates
# and generates a parameter list (or something like that - this shit below looks 
# weird to non-rlang users)

# Define some fixed parameters
data_list = list(s_int = 1.03,
                 s_slope = 2.2,
                 g_int = 8,
                 g_slope = 0.92,
                 sd_g = 0.9,
                 f_r_int = 0.09,
                 f_r_slope = 0.05,
                 f_s_int = 0.1,
                 f_s_slope = 0.005,
                 mu_fd = 9,
                 sd_fd = 2)

# Now, simulate some random intercepts for growth, survival, and offspring production
g_r_int <- rnorm(5, 0, 0.3)
s_r_int <- rnorm(5, 0, 0.7)
f_s_r_int <- rnorm(5, 0, 0.2)

nms <- paste("r_", 1:5, sep = "")

names(g_r_int) <- paste('g_', nms, sep = "")
names(s_r_int) <- paste('s_', nms, sep = "")
names(f_s_r_int) <- paste('f_s_', nms, sep = "")

# The !!! operator used inside of list2 from rlang takes the named vector
# and converts it to a named list. This can be spliced into the data list
# to rapidly make a parameter set suitable for usage in the data_list argument
# of define_kernel

g_params   <- as.list(g_r_int)
s_params   <- as.list(s_r_int)
f_s_params <- as.list(f_s_r_int)

params <- splice(data_list, g_params, s_params, f_s_params)

# define the levels of the hierarchical variable and save them in a named
# list that corresponds to the suffix in the kernel notation
hier_levels <- list(yr = 1:5)

# additional usr_funs to be passed into make_ipm()
inv_logit <- function(sv, int, slope) {
  return(
    1/(1 + exp(-(int + slope * sv)))
  )
}

inv_logit_r <- function(sv, int, slope, r_eff) {
  return(
    1/(1 + exp(-(int + slope * sv + r_eff)))
  )
}

pois_r <- function(sv, int, slope, r_eff) {
  return(
    exp(
      int + slope * sv + r_eff
    )
  )
}


monocarp_sys <- init_ipm('simple_di_stoch_kern') %>%
  define_kernel(
    name = 'P_yr',
    formula = s_g_mult(s_yr, g_yr),
    family = "CC",
    s_yr = inv_logit_r(ht_1, s_int, s_slope, s_r_yr) *
      (1 - inv_logit(ht_1, f_r_int, f_r_slope)),
    g_yr = dnorm(ht_2, mean = mu_g_yr, sd = sd_g) * cell_size_ht,
    mu_g_yr = g_int + g_slope * ht_1 + g_r_yr,
    data_list = params,
    states = list(c('ht')),
    has_hier_effs = TRUE,
    levels_hier_effs = hier_levels,
    evict = TRUE,
    # Note that the suffix is appended here since the growth kernel also has a random intercept.
    evict_fun = truncated_distributions(g_yr,
                                        n_mesh_p = 100)
  ) %>%
  define_kernel(
    "F_yr",
    formula = f_r * f_s_yr * f_d,
    family = "CC",
    f_r = inv_logit(ht_1, f_r_int, f_r_slope),
    f_s_yr = pois_r(ht_1, f_s_int, f_s_slope, f_s_r_yr),
    f_d = dnorm(ht_2, mean = mu_fd, sd = sd_fd) * cell_size_ht,
    data_list = params,
    states = list(c('ht')),
    has_hier_effs = TRUE,
    levels_hier_effs = hier_levels,
    evict = FALSE) %>%
  define_k(
    'K_yr',
    K_yr = P_yr + F_yr,
    family = "IPM",
    data_list = params,
    states = list(c("ht")),
    has_hier_effs = TRUE,
    levels_hier_effs = hier_levels,
    evict = FALSE
  ) %>%
  define_impl(
    make_impl_args_list(
      kernel_names = c("K_yr", "P_yr", "F_yr"),
      int_rule = rep("midpoint", 3),
      dom_start = rep("ht", 3),
      dom_end = rep("ht", 3)
    )
  ) %>%
  define_domains(ht = c(0.2, 40, 100)) %>%
  make_ipm(usr_funs = list(inv_logit = inv_logit,
                           inv_logit_r = inv_logit_r,
                           pois_r = pois_r))


```
    
## Discusion of additional applications

6. bullets for now

    + the `proto_ipm` provides a natural intermediate data structure for user- and database-specified IPMs
    
        - Users could even just export their proto IPM and email to database curators, or provide it in the supplementary materials, thus reducing the logistical overhead of migrating information from publication to, say, PADRINO.
    
    + viable mechanism for reproducing published IPMs without relying on raw data and associated code
    
    + provides a framework for generating user-specified ones that emphasizes the math over the code
    
        - Should eventually become the standard for teaching, as it doesn't abstract away the mathematical underpinnings of the models. It does keep you from screwing up the implementation though.
    
    + 
    
    
# Citation list

1. Bates et al 2015: Fitting mixed effects models using lme4

2. Wood 2011: Fast stable restricted maximum likelihood and marginal likelihood estimates of semiparametric genearlized linear models. 

3. IPMpack paper Metcalf et al.

4. Ellner, Rees & Childs 2016

5. Easterling, Ellner & Dixon 2000

6. Caswell 2001

7. Ramula, Rees & Buckley 2009: Integral projection models perform better for small demographic data sets than matrix population models: a case study of two perennial herbs

8. Compagnoni et al 2020 (hopefully). Plant review, uses ipmr and PADRINO to rebuild selected kernels for re-analysis.


